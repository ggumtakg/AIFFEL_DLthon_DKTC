{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054cba58-a9b5-44be-9beb-bc6ec24ed284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e475cfe-4c6d-4681-ae7a-74ad3307f327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 13:19:19.162407: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-09 13:19:19.170462: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733750359.180364  398855 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733750359.183345  398855 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-09 13:19:19.193597: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, TFElectraForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3305662-6fba-4c88-9286-7666cad00efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>conversation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>야 새꺄 일로와 바 일병 보니까 너네가 이미 노래방 청소했는데 우리가 거기 담당이더...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>민수야 나 수술비가 필요해서 그러는데 5만 원만 빌려줄 수 있을까? 응? 안돼. 나...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>나 이거 할인해 줘 이 상품은 할인 상품이 아니세요. 무슨 소리야? 어제는 됐다고....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>어때? 예쁜 손가락이 곧 없어질 텐데. 림 그리는 사람한테는 손이 생명이에요 그러게...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>이빨을 못쓰게 뽑아버려야겠어 왜 그러십니까 왜긴 네 하는 짓거리가 거슬려서 참을 수...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>9895</td>\n",
       "      <td>이봐, 당신은 만화가 보이십니까? 반환. 다시,이 아기는 너무 씹어 봐요.미래에, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>9896</td>\n",
       "      <td>결혼식을 축하해 주셔서 감사합니다. 물론, 우리 동문은 가장 빨리 가고 있습니다. ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9897</th>\n",
       "      <td>9897</td>\n",
       "      <td>뜨겁다, 무슨 일이야?당신은 그 담배를 피우고있었습니다. 왜 당신은 횡단 보도이지만...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9898</th>\n",
       "      <td>9898</td>\n",
       "      <td>좋아요, 당신의 일이 뭐야? 내 머리카락이 여기 나왔다.양육자 환불이 어렵습니다. ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9899</th>\n",
       "      <td>9899</td>\n",
       "      <td>이봐, 왜 걸어가는거야? 저를보고하는 소리 야? 여기에 너보다 더 많아?이렇게 살면...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx                                       conversation  label\n",
       "0        0  야 새꺄 일로와 바 일병 보니까 너네가 이미 노래방 청소했는데 우리가 거기 담당이더...      2\n",
       "1        1  민수야 나 수술비가 필요해서 그러는데 5만 원만 빌려줄 수 있을까? 응? 안돼. 나...      1\n",
       "2        2  나 이거 할인해 줘 이 상품은 할인 상품이 아니세요. 무슨 소리야? 어제는 됐다고....      3\n",
       "3        3  어때? 예쁜 손가락이 곧 없어질 텐데. 림 그리는 사람한테는 손이 생명이에요 그러게...      0\n",
       "4        4  이빨을 못쓰게 뽑아버려야겠어 왜 그러십니까 왜긴 네 하는 짓거리가 거슬려서 참을 수...      0\n",
       "...    ...                                                ...    ...\n",
       "9895  9895  이봐, 당신은 만화가 보이십니까? 반환. 다시,이 아기는 너무 씹어 봐요.미래에, ...      3\n",
       "9896  9896  결혼식을 축하해 주셔서 감사합니다. 물론, 우리 동문은 가장 빨리 가고 있습니다. ...      3\n",
       "9897  9897  뜨겁다, 무슨 일이야?당신은 그 담배를 피우고있었습니다. 왜 당신은 횡단 보도이지만...      0\n",
       "9898  9898  좋아요, 당신의 일이 뭐야? 내 머리카락이 여기 나왔다.양육자 환불이 어렵습니다. ...      3\n",
       "9899  9899  이봐, 왜 걸어가는거야? 저를보고하는 소리 야? 여기에 너보다 더 많아?이렇게 살면...      3\n",
       "\n",
       "[9900 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 증강 데이터 활용\n",
    "train_data = pd.read_csv('/workspace/train_Augumented_data_preproc_last.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faaf551d-2659-4669-84d9-44dec6be7c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m class_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m협박 대화\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m갈취 대화\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m일반 대화\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 클래스 이름을 숫자로 변환\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(class_mapping)\n\u001b[1;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data = train_data\n",
    "\n",
    "class_mapping = {\n",
    "    \"협박 대화\": 0,\n",
    "    \"갈취 대화\": 1,\n",
    "    \"직장 내 괴롭힘 대화\": 2,\n",
    "    \"기타 괴롭힘 대화\": 3,\n",
    "    \"일반 대화\": 4\n",
    "}\n",
    "\n",
    "# 클래스 이름을 숫자로 변환\n",
    "data['label'] = data['class'].map(class_mapping)\n",
    "data = data.drop(columns=['class'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e18048-7697-4a60-a94f-700ea3c7733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분리\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data['conversation'], data['label'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517bd1bb-10f6-433a-b888-6b31925e6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": label\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81cf38-25df-4f72-9e84-7381a050d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# koelectra 모델 정의\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"monologg/koelectra-base-v3-discriminator\",\n",
    "    num_labels=5,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0602b0-a370-4b08-a1f0-7ed404e60f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06bf12-ca54-4d0b-84c0-ce86664be3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b752cf3-7dc6-4e01-a9b1-2e8d987093b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "texts = [\"이 문장은 협박에 해당합니다.\", \"이 문장은 일반 문장입니다.\"]\n",
    "labels = [[1, 0, 0, 0, 0], [0, 0, 0, 0, 1]]  # Multi-hot encoding\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "\n",
    "train_dataset = TextDataset(texts, labels, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67fb4f-7902-42ff-ac06-c92da5a96336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 및 손실 함수 설정\n",
    "# 옵티마이저와 스케줄러 정의\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "num_training_steps = len(train_loader) * epochs\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=100, num_training_steps=num_training_steps)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9010f-f89e-439a-87cf-dc56ec3cc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, get_scheduler\n",
    "\n",
    "# 하이퍼파라미터\n",
    "epochs = 22\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_loss = float('inf')\n",
    "checkpoint_path = \"/workspace/koelectra_best_model_checkpoint_right1.pth\"  # 체크포인트 저장 경로\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "for epoch in range(epochs):\n",
    "    # Training Loop\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 출력 및 손실 계산\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(correct / total)\n",
    "    scheduler.step()  # 학습률 스케줄러 업데이트\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}\")\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_correct / val_total)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}\")\n",
    "\n",
    "    # Checkpoint 저장\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_val_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch + 1} with val loss {avg_val_loss:.4f}\")\n",
    "\n",
    "# Checkpoint 불러오기 함수\n",
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded. Starting at epoch {start_epoch} with best loss {best_loss:.4f}\")\n",
    "    return model, optimizer, start_epoch, best_loss\n",
    "\n",
    "# 체크포인트 불러오기 예시\n",
    "# model, optimizer, start_epoch, best_loss = load_checkpoint(model, optimizer, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8c969-e564-407f-8b87-0ddd5db3d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 및 정확도 그래프\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), train_losses, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, epochs + 1), val_losses, marker='o', label=\"Validation Loss\", color='red')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs + 1), train_accuracies, marker='o', label=\"Training Accuracy\", color='orange')\n",
    "plt.plot(range(1, epochs + 1), val_accuracies, marker='o', label=\"Validation Accuracy\", color='green')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0cd99-4eec-4000-be1d-e7cdb129cfe6",
   "metadata": {},
   "source": [
    "### F1 score val 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd13f2-b6b2-4017-8f93-398f420be812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import torch\n",
    "\n",
    "# 1. 평가 루프\n",
    "model.eval()  # 모델 평가 모드 전환\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:  # 기존에 학습 루프에서 사용하던 val_loader 활용\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)  # 실제 라벨\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()  # 예측값\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())  # 실제값\n",
    "\n",
    "# 2. F1 Score 및 Classification Report 계산\n",
    "macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "weighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"협박\", \"갈취\", \"직장 내 괴롭힘\", \"기타 괴롭힘\", \"일반 대화\"]))\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68db4e-e4cd-4343-ba76-2d87579ee0ea",
   "metadata": {},
   "source": [
    "## 일반대화 제외 f1 score 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9124c5-44fe-4ad9-8f8b-e5405e7a7df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import torch\n",
    "\n",
    "# 제외할 클래스 정의 (예: '일반 대화' 클래스가 4번이라고 가정)\n",
    "exclude_class = 4\n",
    "\n",
    "# 1. 평가 루프\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 2. 클래스 제외\n",
    "filtered_preds = [pred for pred, label in zip(all_preds, all_labels) if label != exclude_class]\n",
    "filtered_labels = [label for label in all_labels if label != exclude_class]\n",
    "\n",
    "# 제외된 클래스를 반영한 레이블 정의\n",
    "filtered_class_labels = [0, 1, 2, 3]  # 제외된 '일반 대화' 클래스 번호를 제외한 나머지 클래스\n",
    "filtered_target_names = [\"협박\", \"갈취\", \"직장 내 괴롭힘\", \"기타 괴롭힘\"]  # 제외된 클래스 이름 제거\n",
    "\n",
    "# 3. F1 Score 및 Classification Report 계산\n",
    "macro_f1 = f1_score(filtered_labels, filtered_preds, average='macro')\n",
    "weighted_f1 = f1_score(filtered_labels, filtered_preds, average='weighted')\n",
    "\n",
    "print(\"Classification Report (Excluding '일반 대화'):\")\n",
    "print(classification_report(filtered_labels, filtered_preds, labels=filtered_class_labels, target_names=filtered_target_names))\n",
    "print(f\"Macro F1 Score (Excluding '일반 대화'): {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1 Score (Excluding '일반 대화'): {weighted_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a8583-f666-415b-9970-5f6afffb7031",
   "metadata": {},
   "source": [
    "### Test data 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68631fa8-8ddd-487c-90ec-8b4e960a693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preproc_result2 = pd.read_csv('/workspace/test_data_preproc_last.csv')\n",
    "# 욕설까지 필터링 된 test_data 사용\n",
    "data = test_preproc_result2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890bc02-3e18-4adb-995a-69bebd2647a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "data['text'] = data['text'].apply(lambda x: x.strip())\n",
    "\n",
    "class_mapping = {\n",
    "    \"협박 대화\": 0,\n",
    "    \"갈취 대화\": 1,\n",
    "    \"직장 내 괴롭힘 대화\": 2,\n",
    "    \"기타 괴롭힘 대화\": 3,\n",
    "    \"일반 대화\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e79ee-c1af-47a9-96da-5f25efa26b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 테스트 데이터셋 생성\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=4096):  # KoBigBird는 4096 토큰까지 지원\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "# 3. 모델 및 토크나이저 로드\n",
    "model_path = \"/workspace/koelectra_best_model_checkpoint_right1.pth\"\n",
    "model_name = \"monologg/kobigbird-bert-base\"\n",
    "\n",
    "# 토크나이저 및 모델 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "\n",
    "# 체크포인트 로드\n",
    "checkpoint = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 4. 데이터로더 생성\n",
    "test_texts = test_data['text']  # test_data의 conversation 열 사용\n",
    "test_dataset = TestDataset(test_texts, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)  # KoBigBird는 큰 모델이므로 작은 배치 크기 사용\n",
    "\n",
    "# 5. 평가 루프\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94929913-f696-43e3-b37b-002c97994174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 결과 저장\n",
    "test_data['predicted_label'] = all_preds  # 예측 결과를 새로운 열로 추가\n",
    "output_path = \"/workspace/koelectra_best_model_checkpoint_right1.csv\"  # 결과 저장 경로\n",
    "test_data.to_csv(output_path, index=False)\n",
    "print(f\"Predictions saved to {output_path}\")\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202babd-570d-44f5-a513-6324e18b58db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
